{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Zqf4h2KRfd"
      },
      "source": [
        "# Comparative Analysis: Stochastic Gradient Descent and Adam Optimizer for Neural Networks Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0kUpCxIKozh"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLGKqAT7KJZ0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2SdeUgXLQ4E"
      },
      "source": [
        "### Use GPU to speed up the tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OHyp69YKwxC",
        "outputId": "b81df3cf-53cc-4f24-863b-c70c1b6a7a41"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPxIAiyYKx2U"
      },
      "outputs": [],
      "source": [
        "if gpus: \n",
        "  tf.config.experimental.set_memory_growth(gpus[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAIWAIF2UDID",
        "outputId": "55e370ec-5c3b-4bf8-a5b9-02f02a9f8316"
      },
      "outputs": [],
      "source": [
        "import utils as ut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_8tsTgRLNNw"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFBINoWLLKZd"
      },
      "outputs": [],
      "source": [
        "batch_sizes = [16, 32, 64]\n",
        "learning_rates = [0.1, 0.01, 0.001]\n",
        "optimizers = [ut.Optimizer.SGD, ut.Optimizer.Adam]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNyCnbxWK5G6"
      },
      "source": [
        "## Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_91qredK77t",
        "outputId": "ec0ffc14-c06f-4dc1-d8d2-107e915d0973"
      },
      "outputs": [],
      "source": [
        "titanic_data = {}\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "  titanic_data[batch_size] = {}\n",
        "  for learning_rate in learning_rates:\n",
        "    titanic_data[batch_size][learning_rate] = {}\n",
        "    for optimizer in optimizers:\n",
        "      optimizer_name = optimizer.value.name\n",
        "      print(\"====================\")\n",
        "      print(f\"{optimizer_name}: batch_size = {batch_size}; learning_rate = {learning_rate}\")\n",
        "      print(\"====================\")\n",
        "      titanic = ut.Titanic(batch_size, learning_rate, optimizer.value.func)\n",
        "      train, test, val = titanic.data_pipeline()\n",
        "      titanic.compile()\n",
        "      history = titanic.fit()\n",
        "      results = titanic.evaluate()\n",
        "      titanic_data[batch_size][learning_rate][optimizer_name] = (history, results)\n",
        "      print(\"--------------------\")\n",
        "      print(f\"loss: {results[0]}, accuracy: {results[1]}\")\n",
        "      print(\"--------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "Yo0IQ_6icBNL",
        "outputId": "5edd1ff8-2b88-4759-fd6a-a96d7181c1e7"
      },
      "outputs": [],
      "source": [
        "ut.plot(titanic_data, batch_sizes, learning_rates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ohsa9_1K9uP"
      },
      "source": [
        "## Multiclass Image Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuARMkzPK-cD",
        "outputId": "7853b6a5-9bc9-4088-bc6c-0f5374870e94"
      },
      "outputs": [],
      "source": [
        "mnist_data = {}\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "  mnist_data[batch_size] = {}\n",
        "  for learning_rate in learning_rates:\n",
        "    mnist_data[batch_size][learning_rate] = {}\n",
        "    for optimizer in optimizers:\n",
        "      optimizer_name = optimizer.value.name\n",
        "      print(\"====================\")\n",
        "      print(f\"{optimizer_name}: batch_size = {batch_size}; learning_rate = {learning_rate}\")\n",
        "      print(\"====================\")\n",
        "      mnist = ut.MNIST(batch_size, learning_rate, optimizer.value.func)\n",
        "      train, test, val = mnist.data_pipeline()\n",
        "      mnist.compile()\n",
        "      history = mnist.fit()\n",
        "      results = mnist.evaluate()\n",
        "      mnist_data[batch_size][learning_rate][optimizer_name] = (history, results)\n",
        "      print(\"--------------------\")\n",
        "      print(f\"loss: {results[0]}, accuracy: {results[1]}\")\n",
        "      print(\"--------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YgIi8S3gvWL"
      },
      "outputs": [],
      "source": [
        "ut.plot(mnist_data, batch_sizes, learning_rates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPdfi9j_LAIx"
      },
      "source": [
        "## Sentimental Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QMv77jjLBXf"
      },
      "outputs": [],
      "source": [
        "imdb_data = {}\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "  imdb_data[batch_size] = {}\n",
        "  for learning_rate in learning_rates:\n",
        "    imdb_data[batch_size][learning_rate] = {}\n",
        "    for optimizer in optimizers:\n",
        "      optimizer_name = optimizer.value.name\n",
        "      print(\"====================\")\n",
        "      print(f\"{optimizer_name}: batch_size = {batch_size}; learning_rate = {learning_rate}\")\n",
        "      print(\"====================\")\n",
        "      imdb = ut.IMDB(batch_size, learning_rate, optimizer.value.func)\n",
        "      train, test, val = imdb.data_pipeline()\n",
        "      imdb.compile()\n",
        "      history = imdb.fit()\n",
        "      results = imdb.evaluate()\n",
        "      imdb_data[batch_size][learning_rate][optimizer_name] = (history, results)\n",
        "      print(\"--------------------\")\n",
        "      print(f\"loss: {results[0]}, accuracy: {results[1]}\")\n",
        "      print(\"--------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WDn1shvhESs"
      },
      "outputs": [],
      "source": [
        "ut.plot(imdb_data, batch_sizes, learning_rates)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
